{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерируем часть датасета для обучения BERT (для кода, который в репозитории preposition-generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим названия блюд с сайта, собираем наборы  {действие + блюдо}, при помощи правил генерируем связанное предложение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47 = основные блюда \n",
    "# 42 = выпечка и сладкое \n",
    "# 45 = закуски \n",
    "# 76 = итальянская \n",
    "# 91 = русская\n",
    "# 69 = грузинская \n",
    "# 56 = американская\n",
    "# 98 = французская \n",
    "# 72 = европейская\n",
    "# 97 = украинская\n",
    "# 103 = японская\n",
    "# 57 = английская \n",
    "# 83 = мексиканская \n",
    "# 75 = испанская \n",
    "# 96= узбекская "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Мясо в крахмале по-китайски\n",
      "Суп со шпинатом и соусом\n",
      "Креветки в кисло-сладком соусе\n",
      "Битые огурцы\n",
      "Гречка в азиатском стиле\n",
      "Гречневая лапша с курицей терияки\n",
      "Рис с курицей и ананасом\n",
      "Салат из битых огурцов\n",
      "Стеклянная лапша с креветками\n",
      "Китайские квадратики с фаршем\n",
      "Жареный рис по-китайски\n",
      "Куриная грудка в кисло-сладком соусе\n",
      "Фунчоза с овощами и морепродуктами\n",
      "2\n",
      "Говядина по-сычуаньски\n",
      "Китайское печенье с предсказаниями\n",
      "Кисло-сладкие свиные ребра по-китайски\n",
      "Свинина в кисло-сладком соусе с ананасом\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# data = pd.Series()\n",
    "data_list = []\n",
    "\n",
    "# category = [76,91,69,42,47,45]\n",
    "# category = [56,98,72,97,103,57,83,75,96]\n",
    "category = [77]\n",
    "for j in category:\n",
    "    for i in range(10):\n",
    "        url =f'https://hi-chef.ru/api/recipes/?category={j}&page={i}'\n",
    "        print(i)\n",
    "        time.sleep(1)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        res = [i.split('\"title\":')[1].strip('\"') for i in re.findall('\"id\":[0-9]*,\"title\":\"[А-Яа-я -]*\"',soup.text)]\n",
    "\n",
    "        for i in res:\n",
    "            print(i)\n",
    "            data_list.append(i)\n",
    "\n",
    "\n",
    "data_42 = pd.Series(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Мясо в крахмале по-китайски\n",
       "1                     Суп со шпинатом и соусом\n",
       "2               Креветки в кисло-сладком соусе\n",
       "3                                 Битые огурцы\n",
       "4                     Гречка в азиатском стиле\n",
       "5            Гречневая лапша с курицей терияки\n",
       "6                     Рис с курицей и ананасом\n",
       "7                       Салат из битых огурцов\n",
       "8                Стеклянная лапша с креветками\n",
       "9                Китайские квадратики с фаршем\n",
       "10                     Жареный рис по-китайски\n",
       "11        Куриная грудка в кисло-сладком соусе\n",
       "12          Фунчоза с овощами и морепродуктами\n",
       "13                      Говядина по-сычуаньски\n",
       "14          Китайское печенье с предсказаниями\n",
       "15      Кисло-сладкие свиные ребра по-китайски\n",
       "16    Свинина в кисло-сладком соусе с ананасом\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_42.drop_duplicates()\n",
    "data_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_42.to_excel('data_food_names.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем наборы фраз "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['приготовить', 'мясо в крахмале по-китайски'],\n",
       " ['попробовать', 'суп со шпинатом и соусом'],\n",
       " ['продегустировать', 'креветки в кисло-сладком соусе'],\n",
       " ['сфотографировать', 'битые огурцы'],\n",
       " ['научиться делать', 'гречка в азиатском стиле'],\n",
       " ['научиться готовить', 'гречневая лапша с курицей терияки'],\n",
       " ['съесть', 'рис с курицей и ананасом'],\n",
       " ['приготовить', 'салат из битых огурцов'],\n",
       " ['попробовать', 'стеклянная лапша с креветками'],\n",
       " ['продегустировать', 'китайские квадратики с фаршем'],\n",
       " ['сфотографировать', 'жареный рис по-китайски'],\n",
       " ['научиться делать', 'куриная грудка в кисло-сладком соусе'],\n",
       " ['научиться готовить', 'фунчоза с овощами и морепродуктами'],\n",
       " ['съесть', 'говядина по-сычуаньски'],\n",
       " ['приготовить', 'китайское печенье с предсказаниями'],\n",
       " ['попробовать', 'кисло-сладкие свиные ребра по-китайски'],\n",
       " ['продегустировать', 'свинина в кисло-сладком соусе с ананасом']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_42 = pd.read_excel('data_food_names.xlsx')\n",
    "res_tags =[]\n",
    "verb_num = 0\n",
    "verbs = ['приготовить','попробовать','продегустировать', 'сфотографировать', 'научиться делать',\n",
    "         'научиться готовить', 'съесть']\n",
    "for i in data_42.iloc[:][0]:\n",
    "#     print(i)\n",
    "    res_tags.append([verbs[verb_num], i[0].lower() + i[1:]])\n",
    "    verb_num += 1\n",
    "    if verb_num > 6:\n",
    "        verb_num = 0\n",
    "print(len(res_tags))      \n",
    "res_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции ниже пытаются обработать исключения, которые очень мешались мне на пути. Довольно костыльным методом пришлось их решать, но это помогло "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusion(p,p_next):\n",
    "    if (p.word == 'панакота'):\n",
    "        p = morph.parse(p.word)[2]\n",
    "    elif (p_next.word == 'панакота'):\n",
    "        p_next = morph.parse(p_next.word)[2]\n",
    "    return p,p_next\n",
    "\n",
    "             \n",
    "\n",
    "def full_phrase_one(p,j, new_p):\n",
    "    split = j[1].split(p)\n",
    "    \n",
    "    if (split[0]) == j[1]:\n",
    "        p =p.replace('ё','е')\n",
    "        split = j[1].split(p)\n",
    "    try:\n",
    "        normalaze_phrase = ' '.join([j[0],split[0],new_p, split[1]])\n",
    "    except:\n",
    "        normalaze_phrase = ' '.join([j[0],split[0],new_p])\n",
    "    print(normalaze_phrase)\n",
    "    \n",
    "    return normalaze_phrase\n",
    "\n",
    "\n",
    "def full_phrase_two(p,p_next,j, new_p,new_p_next):\n",
    "    base = p+' '+p_next \n",
    "    split = j[1].split(base)\n",
    "\n",
    "    if (split[0]) == j[1]:\n",
    "        base = base.replace('ё','е')\n",
    "        split = j[1].split(base)\n",
    "    try:\n",
    "        normalaze_phrase = ' '.join([j[0],split[0],new_p,new_p_next, split[1]])\n",
    "    except:\n",
    "        normalaze_phrase = ' '.join([j[0],split[0],new_p,new_p_next])\n",
    "    print(normalaze_phrase)\n",
    "    return normalaze_phrase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_dict = ['лазанья']\n",
    "\n",
    "\n",
    "def exclusion_hard(j,p=None,p_next=None):\n",
    "#     часть для одного слова \n",
    "    \n",
    "#     print(f'p_next = {p_next}')\n",
    "    if (p != None) and (p_next == None) or((p == None) and (p_next != None)):\n",
    "        if (p == 'лазанья'):\n",
    "            return full_phrase_one('лазанья', j,'лазанью')\n",
    "        elif (p_next == 'лазанья'):\n",
    "            return full_phrase_one('лазанья', j,'лазанью')\n",
    "        \n",
    "        elif (p == 'панакотта'):\n",
    "            return full_phrase_one('панакотта', j,'панакотту')\n",
    "        elif (p_next == 'панакотта'):\n",
    "            return full_phrase_one('панакотта', j,'панакотту')\n",
    "        \n",
    "#     часть для двух слов \n",
    "    elif (p != None) and (p_next != None):\n",
    "        \n",
    "        if (p == 'лазанья'):\n",
    "            new_p_next = morph.parse(p_next)[0].inflect({\"femn\",\"accs\"}).word\n",
    "            return full_phrase_two('лазанья',p_next,j,'лазанью',new_p_next)\n",
    "        \n",
    "        elif (p_next == 'лазанья'):\n",
    "            new_p = morph.parse(p)[0].inflect({\"femn\",\"accs\"}).word\n",
    "            return full_phrase_two(p,'лазанья',j,new_p,'лазанью')\n",
    "        \n",
    "        if (p == 'панакотта'):\n",
    "            new_p_next = morph.parse(p_next)[0].inflect({\"femn\",\"accs\"}).word\n",
    "            return full_phrase_two('панакотта',p_next,j,'панакотту',new_p_next)\n",
    "        \n",
    "        elif (p_next == 'панакотта'):\n",
    "            new_p = morph.parse(p)[0].inflect({\"femn\",\"accs\"}).word\n",
    "            return full_phrase_two(p,'панакотта',j,new_p,'панакотту')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def replace_word(j):\n",
    "    if 'панна  котта' in j[1]:\n",
    "        return j[1].replace('панна  котта', 'панакота')\n",
    "    elif 'панакотта' in j[1]:\n",
    "        return j[1].replace('панакотта', 'панакота')\n",
    "    elif 'панна-котта' in j[1]:\n",
    "        return j[1].replace('панна-котта', 'панакота')\n",
    "    else:\n",
    "        return j[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions_plur = ['панкейки','капкейки','чизкейки','маффины']\n",
    "def exceptions(word):\n",
    "#     print(word)\n",
    "    if word.word in exceptions_plur:\n",
    "        print('++++++')\n",
    "        try:\n",
    "            return word.inflect({\"accs\",'plur'}).word\n",
    "        except:\n",
    "            return word.word\n",
    "    else:\n",
    "        return word.word\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже мы описываем правилами все возможные варинаты склонения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "попробовать  суп  со шпинатом и соусом\n",
      "продегустировать  креветки  в кисло-сладком соусе\n",
      "сфотографировать  битые огурцы \n",
      "научиться делать  гречку  в азиатском стиле\n",
      "научиться готовить  гречневую лапшу  с курицей терияки\n",
      "съесть  рис  с курицей и ананасом\n",
      "приготовить  салат  из битых огурцов\n",
      "попробовать  стеклянную лапшу  с креветками\n",
      "продегустировать  китайские квадратики  с фаршем\n",
      "сфотографировать жареный  рис  по-китайски\n",
      "научиться делать  куриную грудку  в кисло-сладком соусе\n",
      "научиться готовить  фунчоза  с овощами и морепродуктами\n",
      "съесть  говядину  по-сычуаньски\n",
      "приготовить  китайское печенье  с предсказаниями\n",
      "продегустировать  свинину  в кисло-сладком соусе с ананасом\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "results = []\n",
    "\n",
    "for j in res_tags[1:]:\n",
    "    j[1] = replace_word(j)\n",
    "    text = j[1].split()\n",
    "    \n",
    "#     print(text)\n",
    "    \n",
    "    for i in range(len(text))[:-1]:\n",
    "        p = morph.parse(text[i])[0]\n",
    "        p_next = morph.parse(text[i+1])[0]\n",
    "        p,p_next = exclusion(p,p_next)\n",
    "        if ('ADJF' in p.tag) and ('NOUN' in p_next.tag) and ('sing' in p_next.tag) and ('nomn' in p_next.tag):\n",
    "            if (p_next.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "            \n",
    "            \n",
    "            elif ('masc' in p.tag) or ('neut' in p.tag):\n",
    "                normalaze_phrase = full_phrase_two(p.word,p_next.word,j, p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_two(p.word,p_next.word,j,p.inflect({'sing',\"accs\"}).word,p_next.inflect({'sing',\"accs\"}).word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            break\n",
    "\n",
    "#  сущ + прилаг (наоборот от первого if)    \n",
    "        if ('ADJF' in p_next.tag) and ('NOUN' in p.tag) and ('sing' in p.tag) and ('nomn' in p.tag):\n",
    "            if (p.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            elif ('masc' in p.tag) or ('neut' in p.tag):\n",
    "                normalaze_phrase = full_phrase_two(p.word,p_next.word,j, p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_two(p.word,p_next.word,j, p.inflect({'sing',\"accs\"}).word,p_next.inflect({'sing',\"accs\"}).word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            break\n",
    "    \n",
    "            \n",
    "        elif ('ADJF' in p.tag) and ('NOUN' in p_next.tag) and ('plur' in p_next.tag) and ('nomn' in p_next.tag):\n",
    "            if (p_next.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "            \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_two(p.word,p_next.word,j, p.word,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "    \n",
    "            break\n",
    "                               \n",
    "#           отдельно проверям целую строку и отдельно последний символ.\n",
    "        elif ('NOUN' in p.tag) and ('sing' in p.tag): #одно сущ  (без последнего слова)\n",
    "            \n",
    "            if (p.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p=p.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            elif (p.word in exceptions_plur):\n",
    "                normalaze_phrase = full_phrase_one(p.word,j,exceptions(p))\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                \n",
    "                \n",
    "            elif ('femn' in p.tag):#женского рода\n",
    "                normalaze_phrase = full_phrase_one(p.word,j,p.inflect({'sing',\"accs\"}).word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_one(p.word,j,p.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "\n",
    "            break\n",
    "            \n",
    "           \n",
    "        elif ('NOUN' in p_next.tag) and ('sing' in p_next.tag) :\n",
    "            if (p_next.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p_next=p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            elif (p_next.word in exceptions_plur):\n",
    "                normalaze_phrase = full_phrase_one(p_next.word,j,exceptions(p_next))\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                \n",
    "            elif ('femn' in p_next.tag):#женского рода\n",
    "                normalaze_phrase = full_phrase_one(p_next.word,j,p_next.inflect({'sing',\"accs\"}).word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_one(p_next.word,j,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            break\n",
    "        \n",
    "        \n",
    "        elif ('NOUN' in p.tag) and ('plur' in p.tag) and ('nomn' in p.tag): #одно сущ  м.ч (без последнего слова)\n",
    "            if (p.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p=p.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_one(p.word,j,p.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")                            \n",
    "                                      \n",
    "            break\n",
    "            \n",
    "           \n",
    "        elif ('NOUN' in p_next.tag) and ('plur' in p_next.tag) and ('nomn' in p_next.tag):\n",
    "            if (p_next.word in exclusion_dict):\n",
    "                normalaze_phrase = exclusion_hard(j,p_next=p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "                               \n",
    "            else:\n",
    "                normalaze_phrase = full_phrase_one(p_next.word,j,p_next.word)\n",
    "                results.append(f\"{'[' + ', '.join(j) + ']'} => {normalaze_phrase.replace('  ',' ')}\")\n",
    "\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. прилаг + сущ (ед, ж.р.) -> оба меняются в В.п. \n",
    "# 2. прилаг + сущ (ед, м.р. И вроде с.р.) ->  не меняется \n",
    "# 3. прилаг + сущ (мн) - > не меняется \n",
    "# 4. сущ (ед) -> меняется сущ в В.п.\n",
    "# 5. сущ (мн)- > не меняется \n",
    "# 6. сущ (название) -> вроде не меняется "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_tags = []\n",
    "output = []\n",
    "for i in results:\n",
    "    input_tags.append(i.split('=>')[0])\n",
    "    output.append(i.split('=>')[1])\n",
    "\n",
    "data_in = pd.Series(input_tags)\n",
    "data_out = pd.Series(output)\n",
    "\n",
    "data_res = pd.DataFrame(zip(data_in,data_out))\n",
    "\n",
    "data_res = data_res.rename({0: 'inputs', 1: 'outputs'}, axis=1)\n",
    "\n",
    "\n",
    "data_res.to_excel('grammar_outputs_food.xlsx', sheet_name = 'data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
